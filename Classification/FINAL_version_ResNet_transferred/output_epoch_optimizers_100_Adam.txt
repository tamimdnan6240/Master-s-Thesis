Follwing classes are there : 
 ['Alligator Cracks', 'Longitudinal Cracks', 'Transverse Cracks']
data length: 132
Length of Train Data : 92
Length of Validation Data : 40
Transverse Cracks Alligator Cracks Transverse Cracks Transverse Cracks Longitudinal Cracks Alligator Cracks Alligator Cracks Transverse Cracks Transverse Cracks Alligator Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks Transverse Cracks Transverse Cracks Transverse Cracks Alligator Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Longitudinal Cracks Longitudinal Cracks Alligator Cracks Transverse Cracks Transverse Cracks Transverse Cracks Alligator Cracks
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=512, out_features=3, bias=True)
    (3): Softmax(dim=1)
    (4): Dropout(p=0.5, inplace=False)
  )
)
epoch: 0: train_loss: 1.1236756245295207, train_acc: 0.3913690447807312, val_loss: 1.0883772373199463, val_acc: 0.4375
epoch: 1: train_loss: 1.1811387141545615, train_acc: 0.3556547661622365, val_loss: 1.1561235189437866, val_acc: 0.390625
epoch: 2: train_loss: 1.1739743947982788, train_acc: 0.4553571442763011, val_loss: 1.0197854042053223, val_acc: 0.53125
epoch: 3: train_loss: 1.187196522951126, train_acc: 0.375, val_loss: 1.0667229890823364, val_acc: 0.484375
epoch: 4: train_loss: 1.194218428929647, train_acc: 0.2723214328289032, val_loss: 1.1138030886650085, val_acc: 0.4375
epoch: 5: train_loss: 1.1998021536403234, train_acc: 0.3883928557236989, val_loss: 1.0670472979545593, val_acc: 0.484375
epoch: 6: train_loss: 1.1893065316336495, train_acc: 0.3452380994955699, val_loss: 1.067050039768219, val_acc: 0.484375
epoch: 7: train_loss: 1.18641330798467, train_acc: 0.3660714228947957, val_loss: 1.0201866924762726, val_acc: 0.53125
epoch: 8: train_loss: 1.1938283046086628, train_acc: 0.3586309552192688, val_loss: 1.0670581459999084, val_acc: 0.484375
epoch: 9: train_loss: 1.179829659064611, train_acc: 0.4330357114473979, val_loss: 1.0670527219772339, val_acc: 0.484375
epoch: 10: train_loss: 1.1824508417736401, train_acc: 0.3690476218859355, val_loss: 1.1139175295829773, val_acc: 0.4375
epoch: 11: train_loss: 1.1858055873049629, train_acc: 0.3095238109429677, val_loss: 1.0201643109321594, val_acc: 0.53125
epoch: 12: train_loss: 1.1883719043853955, train_acc: 0.3720238109429677, val_loss: 1.0669296979904175, val_acc: 0.484375
epoch: 13: train_loss: 1.1866178101017362, train_acc: 0.3422619005044301, val_loss: 1.017244279384613, val_acc: 0.53125
epoch: 14: train_loss: 1.1838991231388514, train_acc: 0.3943452338377635, val_loss: 1.0338916778564453, val_acc: 0.578125
epoch: 15: train_loss: 1.1754424658914406, train_acc: 0.3883928557236989, val_loss: 0.9950969815254211, val_acc: 0.53125
epoch: 16: train_loss: 1.1619536058575497, train_acc: 0.4925595223903656, val_loss: 0.8763602375984192, val_acc: 0.625
epoch: 17: train_loss: 1.1496277341136225, train_acc: 0.4553571442763011, val_loss: 0.940972238779068, val_acc: 0.5625
epoch: 18: train_loss: 1.136733582145289, train_acc: 0.4880952338377635, val_loss: 0.8587916791439056, val_acc: 0.796875
epoch: 19: train_loss: 1.1217985222736993, train_acc: 0.5148809552192688, val_loss: 0.9341005384922028, val_acc: 0.578125
epoch: 20: train_loss: 1.1115369106095931, train_acc: 0.4092261890570323, val_loss: 0.7834569811820984, val_acc: 0.75
epoch: 21: train_loss: 1.0944496573823868, train_acc: 0.5357142885526022, val_loss: 0.7677123844623566, val_acc: 0.875
epoch: 22: train_loss: 1.0789667411126949, train_acc: 0.538690467675527, val_loss: 0.8193674683570862, val_acc: 0.65625
epoch: 23: train_loss: 1.0677958784831894, train_acc: 0.4538690447807312, val_loss: 0.7668508291244507, val_acc: 0.828125
epoch: 24: train_loss: 1.0533062704404192, train_acc: 0.6071428656578064, val_loss: 0.7976209223270416, val_acc: 0.75
epoch: 25: train_loss: 1.0429684366935337, train_acc: 0.4747023781140645, val_loss: 0.7444917857646942, val_acc: 0.828125
epoch: 26: train_loss: 1.0313337077329185, train_acc: 0.5401785671710968, val_loss: 0.7771813571453094, val_acc: 0.75
epoch: 27: train_loss: 1.020579866000584, train_acc: 0.5133928656578064, val_loss: 0.7071943581104279, val_acc: 0.828125
epoch: 28: train_loss: 1.0107749796461785, train_acc: 0.5163690447807312, val_loss: 0.7715091407299042, val_acc: 0.78125
epoch: 29: train_loss: 1.0013552043173048, train_acc: 0.519345243771871, val_loss: 0.6708603799343109, val_acc: 0.921875
epoch: 30: train_loss: 0.9904782470836434, train_acc: 0.601190467675527, val_loss: 0.6297983229160309, val_acc: 0.9375
epoch: 31: train_loss: 0.9827337774137656, train_acc: 0.4880952338377635, val_loss: 0.6884120106697083, val_acc: 0.875
epoch: 32: train_loss: 0.9736648665534124, train_acc: 0.5639880895614624, val_loss: 0.6378274261951447, val_acc: 0.921875
epoch: 33: train_loss: 0.9666845868615543, train_acc: 0.53125, val_loss: 0.7028361558914185, val_acc: 0.84375
epoch: 34: train_loss: 0.9574053855169388, train_acc: 0.6220238010088602, val_loss: 0.7060920298099518, val_acc: 0.859375
epoch: 35: train_loss: 0.9509207115129189, train_acc: 0.5014880895614624, val_loss: 0.6355946660041809, val_acc: 0.921875
epoch: 36: train_loss: 0.9438054609943081, train_acc: 0.5193452338377634, val_loss: 0.6595342755317688, val_acc: 0.90625
epoch: 37: train_loss: 0.9377827550235548, train_acc: 0.5267857114473978, val_loss: 0.7113119959831238, val_acc: 0.859375
epoch: 38: train_loss: 0.9325954562578446, train_acc: 0.4895833333333333, val_loss: 0.6610154509544373, val_acc: 0.890625
epoch: 39: train_loss: 0.9296964933474859, train_acc: 0.3913690447807312, val_loss: 0.6626262962818146, val_acc: 0.90625
epoch: 40: train_loss: 0.9254028632388853, train_acc: 0.4360119005044301, val_loss: 0.6324287056922913, val_acc: 0.921875
epoch: 41: train_loss: 0.9210782122044338, train_acc: 0.4910714328289032, val_loss: 0.6591917872428894, val_acc: 0.90625
epoch: 42: train_loss: 0.9180606266324836, train_acc: 0.4181547562281291, val_loss: 0.745494931936264, val_acc: 0.84375
epoch: 43: train_loss: 0.9149102067405529, train_acc: 0.4345238109429677, val_loss: 0.6542885303497314, val_acc: 0.90625
epoch: 44: train_loss: 0.9101877397961088, train_acc: 0.5252976218859354, val_loss: 0.6365909278392792, val_acc: 0.9375
epoch: 45: train_loss: 0.9048322737216951, train_acc: 0.5580357114473978, val_loss: 0.6532593667507172, val_acc: 0.90625
epoch: 46: train_loss: 0.9011819388004061, train_acc: 0.4464285671710968, val_loss: 0.60736083984375, val_acc: 0.953125
epoch: 47: train_loss: 0.8973046027951771, train_acc: 0.4866071442763011, val_loss: 0.7093532085418701, val_acc: 0.859375
epoch: 48: train_loss: 0.8920101223348761, train_acc: 0.5684523781140646, val_loss: 0.6972265839576721, val_acc: 0.859375
epoch: 49: train_loss: 0.8889387289683025, train_acc: 0.4523809552192688, val_loss: 0.6237653493881226, val_acc: 0.953125
epoch: 50: train_loss: 0.8850045379470376, train_acc: 0.5342261989911398, val_loss: 0.6606339514255524, val_acc: 0.890625
epoch: 51: train_loss: 0.881010141892311, train_acc: 0.5639880895614624, val_loss: 0.653811514377594, val_acc: 0.90625
epoch: 52: train_loss: 0.878109208068008, train_acc: 0.4866071442763011, val_loss: 0.6046282052993774, val_acc: 0.953125
epoch: 53: train_loss: 0.8746353777838343, train_acc: 0.543154756228129, val_loss: 0.6047006845474243, val_acc: 0.953125
epoch: 54: train_loss: 0.8711437799713828, train_acc: 0.4985119005044301, val_loss: 0.6132158041000366, val_acc: 0.953125
epoch: 55: train_loss: 0.8679951642240796, train_acc: 0.5580357114473978, val_loss: 0.6557191610336304, val_acc: 0.90625
epoch: 56: train_loss: 0.8640850524456181, train_acc: 0.5773809552192688, val_loss: 0.601335346698761, val_acc: 0.953125
epoch: 57: train_loss: 0.861435431858589, train_acc: 0.523809532324473, val_loss: 0.625730037689209, val_acc: 0.921875
epoch: 58: train_loss: 0.8582895472224823, train_acc: 0.513392855723699, val_loss: 0.6124773919582367, val_acc: 0.953125
epoch: 59: train_loss: 0.856409239768982, train_acc: 0.4464285671710968, val_loss: 0.658766895532608, val_acc: 0.90625
epoch: 60: train_loss: 0.852544998210636, train_acc: 0.586309532324473, val_loss: 0.6133477091789246, val_acc: 0.953125
epoch: 61: train_loss: 0.8483726032959518, train_acc: 0.625, val_loss: 0.6118897497653961, val_acc: 0.9375
epoch: 62: train_loss: 0.8463114913178499, train_acc: 0.5, val_loss: 0.6579397022724152, val_acc: 0.890625
epoch: 63: train_loss: 0.8434431528051693, train_acc: 0.5416666666666666, val_loss: 0.6065747439861298, val_acc: 0.953125
epoch: 64: train_loss: 0.8410134431643363, train_acc: 0.543154756228129, val_loss: 0.6213929057121277, val_acc: 0.921875
epoch: 65: train_loss: 0.8382846845520867, train_acc: 0.5297619005044302, val_loss: 0.6582092046737671, val_acc: 0.890625
epoch: 66: train_loss: 0.8359131394927182, train_acc: 0.5297619005044302, val_loss: 0.6760457456111908, val_acc: 0.90625
epoch: 67: train_loss: 0.8334936978770237, train_acc: 0.5639880895614624, val_loss: 0.6076268255710602, val_acc: 0.9375
epoch: 68: train_loss: 0.8307668583980505, train_acc: 0.5639880895614624, val_loss: 0.639037549495697, val_acc: 0.890625
epoch: 69: train_loss: 0.827249063480468, train_acc: 0.6622023781140646, val_loss: 0.6630580127239227, val_acc: 0.890625
epoch: 70: train_loss: 0.8257197278766004, train_acc: 0.4672619005044301, val_loss: 0.6580264568328857, val_acc: 0.890625
epoch: 71: train_loss: 0.8247045640040327, train_acc: 0.4330357114473979, val_loss: 0.6299013793468475, val_acc: 0.953125
epoch: 72: train_loss: 0.8228595515364381, train_acc: 0.5297619005044302, val_loss: 0.6615601181983948, val_acc: 0.890625
epoch: 73: train_loss: 0.8212217436180458, train_acc: 0.5074404776096344, val_loss: 0.6570533514022827, val_acc: 0.90625
epoch: 74: train_loss: 0.8195916867256164, train_acc: 0.5014880895614624, val_loss: 0.6003648936748505, val_acc: 0.953125
epoch: 75: train_loss: 0.817851345528636, train_acc: 0.549107144276301, val_loss: 0.6047710180282593, val_acc: 0.953125
epoch: 76: train_loss: 0.8166414107079113, train_acc: 0.5104166666666666, val_loss: 0.6861991286277771, val_acc: 0.890625
epoch: 77: train_loss: 0.8162730267414678, train_acc: 0.4241071442763011, val_loss: 0.6181113719940186, val_acc: 0.9375
epoch: 78: train_loss: 0.8156608104202817, train_acc: 0.4598214228947957, val_loss: 0.6497473120689392, val_acc: 0.90625
epoch: 79: train_loss: 0.8133739528556664, train_acc: 0.569940467675527, val_loss: 0.64818274974823, val_acc: 0.90625
epoch: 80: train_loss: 0.8115952476061911, train_acc: 0.5401785671710968, val_loss: 0.6481436789035797, val_acc: 0.90625
epoch: 81: train_loss: 0.8109653214129005, train_acc: 0.4241071442763011, val_loss: 0.6710064709186554, val_acc: 0.90625
epoch: 82: train_loss: 0.8099152859913775, train_acc: 0.4568452338377635, val_loss: 0.6500820517539978, val_acc: 0.90625
epoch: 83: train_loss: 0.8075264820030755, train_acc: 0.5952380895614624, val_loss: 0.6628453135490417, val_acc: 0.890625
epoch: 84: train_loss: 0.8059554992937572, train_acc: 0.5208333333333334, val_loss: 0.6100024282932281, val_acc: 0.953125
epoch: 85: train_loss: 0.8040213931438533, train_acc: 0.5684523781140646, val_loss: 0.6567173302173615, val_acc: 0.890625
epoch: 86: train_loss: 0.8025242416794728, train_acc: 0.5342261989911398, val_loss: 0.6500147879123688, val_acc: 0.90625
epoch: 87: train_loss: 0.8013233680165175, train_acc: 0.543154756228129, val_loss: 0.6045048832893372, val_acc: 0.953125
epoch: 88: train_loss: 0.800100410475713, train_acc: 0.4895833333333333, val_loss: 0.6592667698860168, val_acc: 0.890625
epoch: 89: train_loss: 0.7981245970284496, train_acc: 0.6026785771052042, val_loss: 0.6444089710712433, val_acc: 0.890625
epoch: 90: train_loss: 0.7973141611277402, train_acc: 0.4880952338377635, val_loss: 0.6045054793357849, val_acc: 0.953125
epoch: 91: train_loss: 0.7963108921396559, train_acc: 0.511904756228129, val_loss: 0.6015291213989258, val_acc: 0.953125
epoch: 92: train_loss: 0.7948783512183841, train_acc: 0.5446428656578064, val_loss: 0.6620902121067047, val_acc: 0.890625
epoch: 93: train_loss: 0.793622778028461, train_acc: 0.5193452338377634, val_loss: 0.6981658637523651, val_acc: 0.859375
epoch: 94: train_loss: 0.7925013441788523, train_acc: 0.523809532324473, val_loss: 0.6151507496833801, val_acc: 0.9375
epoch: 95: train_loss: 0.7909011133015156, train_acc: 0.5505952338377634, val_loss: 0.6161415874958038, val_acc: 0.9375
epoch: 96: train_loss: 0.7888644036558485, train_acc: 0.6666666666666666, val_loss: 0.6128576099872589, val_acc: 0.9375
epoch: 97: train_loss: 0.7877530447479819, train_acc: 0.5178571343421936, val_loss: 0.7393041551113129, val_acc: 0.8125
epoch: 98: train_loss: 0.7871164524996723, train_acc: 0.4702380895614624, val_loss: 0.6584678888320923, val_acc: 0.890625
epoch: 99: train_loss: 0.7862571299076082, train_acc: 0.4985119005044301, val_loss: 0.6501078903675079, val_acc: 0.90625
1.0925305485725403 0.4375
GroundTruth:  Alligator Cracks Alligator Cracks Alligator Cracks Alligator Cracks
Accuracy of the network on the test images: 48 %
Accuracy for class: Alligator Cracks is 0.0 %
Accuracy for class: Longitudinal Cracks is 85.7 %
Accuracy for class: Transverse Cracks is 26.7 %
