cpu
Follwing classes are there : 
 ['Alligator Cracks', 'Longitudinal Cracks', 'Transverse Cracks']
data length: 132
Length of Train Data : 92
Length of Validation Data : 40
Transverse Cracks Transverse Cracks Alligator Cracks Alligator Cracks Alligator Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks Alligator Cracks Alligator Cracks Longitudinal Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks Transverse Cracks Alligator Cracks Longitudinal Cracks Alligator Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Longitudinal Cracks Longitudinal Cracks Transverse Cracks Alligator Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=512, out_features=3, bias=True)
    (3): Softmax(dim=1)
    (4): Dropout(p=0.5, inplace=False)
  )
)
epoch: 0: train_loss: 1.1181786457697551, train_acc: 0.3511904776096344, val_loss: 1.1051220297813416, val_acc: 0.25
epoch: 1: train_loss: 1.139411230882009, train_acc: 0.3139880994955699, val_loss: 1.107951045036316, val_acc: 0.109375
epoch: 2: train_loss: 1.1515976587931316, train_acc: 0.3258928557236989, val_loss: 1.1010501980781555, val_acc: 0.28125
epoch: 3: train_loss: 1.1513481338818867, train_acc: 0.2723214328289032, val_loss: 1.1028062105178833, val_acc: 0.25
epoch: 4: train_loss: 1.1453957716623941, train_acc: 0.3913690447807312, val_loss: 1.1005218029022217, val_acc: 0.359375
epoch: 5: train_loss: 1.1504152682092454, train_acc: 0.3258928557236989, val_loss: 1.094496726989746, val_acc: 0.46875
epoch: 6: train_loss: 1.1473327931903656, train_acc: 0.4211309552192688, val_loss: 1.095176100730896, val_acc: 0.28125
epoch: 7: train_loss: 1.1434814383586247, train_acc: 0.4136904776096344, val_loss: 1.0996378064155579, val_acc: 0.375
epoch: 8: train_loss: 1.1443983846240573, train_acc: 0.3229166666666667, val_loss: 1.0943771600723267, val_acc: 0.390625
epoch: 9: train_loss: 1.15144681930542, train_acc: 0.2529761890570323, val_loss: 1.0940159559249878, val_acc: 0.421875
epoch: 10: train_loss: 1.1483152165557398, train_acc: 0.4285714228947957, val_loss: 1.0862630605697632, val_acc: 0.546875
epoch: 11: train_loss: 1.1432457831170824, train_acc: 0.3779761890570323, val_loss: 1.0862869024276733, val_acc: 0.46875
epoch: 12: train_loss: 1.1402717339686856, train_acc: 0.3764880994955699, val_loss: 1.0852274298667908, val_acc: 0.515625
epoch: 13: train_loss: 1.1406793367295038, train_acc: 0.3348214328289032, val_loss: 1.0905736088752747, val_acc: 0.453125
epoch: 14: train_loss: 1.138119241926405, train_acc: 0.3764880994955699, val_loss: 1.0845884084701538, val_acc: 0.484375
epoch: 15: train_loss: 1.1374619106451669, train_acc: 0.3928571442763011, val_loss: 1.08541738986969, val_acc: 0.484375
epoch: 16: train_loss: 1.1346344784194347, train_acc: 0.4375, val_loss: 1.0766155123710632, val_acc: 0.640625
epoch: 17: train_loss: 1.131248218041879, train_acc: 0.3839285721381505, val_loss: 1.0818894505500793, val_acc: 0.4375
epoch: 18: train_loss: 1.1298374585938034, train_acc: 0.3482142885526021, val_loss: 1.0875985026359558, val_acc: 0.4375
epoch: 19: train_loss: 1.1287377675374348, train_acc: 0.4032738109429677, val_loss: 1.0891375541687012, val_acc: 0.390625
epoch: 20: train_loss: 1.1290458497546967, train_acc: 0.4092261989911397, val_loss: 1.0845664739608765, val_acc: 0.40625
epoch: 21: train_loss: 1.1294163447437862, train_acc: 0.3392857114473979, val_loss: 1.0795239210128784, val_acc: 0.484375
epoch: 22: train_loss: 1.1307791333267652, train_acc: 0.3392857114473979, val_loss: 1.0795245170593262, val_acc: 0.4375
epoch: 23: train_loss: 1.1279918915695613, train_acc: 0.4375, val_loss: 1.088428020477295, val_acc: 0.421875
epoch: 24: train_loss: 1.1262795654932656, train_acc: 0.4479166666666667, val_loss: 1.0781829953193665, val_acc: 0.4375
epoch: 25: train_loss: 1.1256126195956497, train_acc: 0.4032738109429677, val_loss: 1.0657475590705872, val_acc: 0.578125
epoch: 26: train_loss: 1.1247741940580767, train_acc: 0.3377976218859355, val_loss: 1.0773479342460632, val_acc: 0.4375
epoch: 27: train_loss: 1.1232829477105821, train_acc: 0.40625, val_loss: 1.076374113559723, val_acc: 0.453125
epoch: 28: train_loss: 1.122508270987149, train_acc: 0.3526785721381505, val_loss: 1.0819019675254822, val_acc: 0.421875
epoch: 29: train_loss: 1.1225937022103203, train_acc: 0.3154761890570323, val_loss: 1.0645134449005127, val_acc: 0.578125
epoch: 30: train_loss: 1.1238298928865822, train_acc: 0.3273809552192688, val_loss: 1.0854427814483643, val_acc: 0.390625
epoch: 31: train_loss: 1.1237114419539769, train_acc: 0.3497023781140645, val_loss: 1.0809940695762634, val_acc: 0.5
epoch: 32: train_loss: 1.1241554033876668, train_acc: 0.3586309552192688, val_loss: 1.060374915599823, val_acc: 0.5625
epoch: 33: train_loss: 1.1234623871597589, train_acc: 0.4032738109429677, val_loss: 1.0824722051620483, val_acc: 0.375
epoch: 34: train_loss: 1.12287433942159, train_acc: 0.3720238109429677, val_loss: 1.0687084197998047, val_acc: 0.546875
epoch: 35: train_loss: 1.1229098781391427, train_acc: 0.3452380994955699, val_loss: 1.0795935988426208, val_acc: 0.421875
epoch: 36: train_loss: 1.1227401387584102, train_acc: 0.3497023781140645, val_loss: 1.085155963897705, val_acc: 0.328125
epoch: 37: train_loss: 1.1230721808316413, train_acc: 0.3452380994955699, val_loss: 1.0708643198013306, val_acc: 0.515625
epoch: 38: train_loss: 1.1227364152924626, train_acc: 0.3720238109429677, val_loss: 1.0746496319770813, val_acc: 0.46875
epoch: 39: train_loss: 1.122748682896296, train_acc: 0.3958333333333333, val_loss: 1.0707337260246277, val_acc: 0.46875
epoch: 40: train_loss: 1.1220906149081098, train_acc: 0.4151785671710968, val_loss: 1.0653014779090881, val_acc: 0.515625
epoch: 41: train_loss: 1.12158749595521, train_acc: 0.4494047661622365, val_loss: 1.0806804895401, val_acc: 0.375
epoch: 42: train_loss: 1.1220300973847854, train_acc: 0.3511904776096344, val_loss: 1.0724214315414429, val_acc: 0.46875
epoch: 43: train_loss: 1.1216321542407526, train_acc: 0.3377976218859355, val_loss: 1.0803136825561523, val_acc: 0.375
epoch: 44: train_loss: 1.1208307442841705, train_acc: 0.3556547661622365, val_loss: 1.059696614742279, val_acc: 0.5625
epoch: 45: train_loss: 1.1198224667189778, train_acc: 0.4255952338377635, val_loss: 1.0799548029899597, val_acc: 0.421875
epoch: 46: train_loss: 1.119156556772002, train_acc: 0.4002976218859355, val_loss: 1.0649719834327698, val_acc: 0.46875
epoch: 47: train_loss: 1.1188389021489356, train_acc: 0.3809523781140645, val_loss: 1.069487988948822, val_acc: 0.46875
epoch: 48: train_loss: 1.1170345317749748, train_acc: 0.4880952338377635, val_loss: 1.0674967765808105, val_acc: 0.46875
epoch: 49: train_loss: 1.1167196146647134, train_acc: 0.4419642885526021, val_loss: 1.0684238076210022, val_acc: 0.421875
epoch: 50: train_loss: 1.1166578889672272, train_acc: 0.3482142885526021, val_loss: 1.0680057406425476, val_acc: 0.46875
epoch: 51: train_loss: 1.1175112166465857, train_acc: 0.3005952388048172, val_loss: 1.0752754211425781, val_acc: 0.421875
epoch: 52: train_loss: 1.1166370589778107, train_acc: 0.4136904776096344, val_loss: 1.0535966157913208, val_acc: 0.515625
epoch: 53: train_loss: 1.1168320907486808, train_acc: 0.3497023781140645, val_loss: 1.0653437376022339, val_acc: 0.46875
epoch: 54: train_loss: 1.1171105507648351, train_acc: 0.3005952388048172, val_loss: 1.052238404750824, val_acc: 0.515625
epoch: 55: train_loss: 1.1174110564447584, train_acc: 0.3169642885526021, val_loss: 1.0610932111740112, val_acc: 0.46875
epoch: 56: train_loss: 1.117601137412222, train_acc: 0.3675595223903656, val_loss: 1.0680251717567444, val_acc: 0.46875
epoch: 57: train_loss: 1.1186139830227555, train_acc: 0.2738095223903656, val_loss: 1.0594789385795593, val_acc: 0.46875
epoch: 58: train_loss: 1.117308669171091, train_acc: 0.4895833333333333, val_loss: 1.0709636211395264, val_acc: 0.421875
epoch: 59: train_loss: 1.116540864109993, train_acc: 0.4077380895614624, val_loss: 1.0617570281028748, val_acc: 0.46875
epoch: 60: train_loss: 1.115569818866709, train_acc: 0.4211309552192688, val_loss: 1.0563743114471436, val_acc: 0.515625
epoch: 61: train_loss: 1.1153635574925331, train_acc: 0.3705357114473979, val_loss: 1.0693637132644653, val_acc: 0.421875
epoch: 62: train_loss: 1.1145888339905512, train_acc: 0.4270833333333333, val_loss: 1.0798203349113464, val_acc: 0.375
epoch: 63: train_loss: 1.1140853073447943, train_acc: 0.3169642885526021, val_loss: 1.0664367079734802, val_acc: 0.46875
epoch: 64: train_loss: 1.1142733610593356, train_acc: 0.3511904776096344, val_loss: 1.070302963256836, val_acc: 0.421875
epoch: 65: train_loss: 1.1139057435170567, train_acc: 0.3571428557236989, val_loss: 1.0708208680152893, val_acc: 0.421875
epoch: 66: train_loss: 1.113980270143765, train_acc: 0.3616071442763011, val_loss: 1.048922061920166, val_acc: 0.515625
epoch: 67: train_loss: 1.1133974217901044, train_acc: 0.3779761890570323, val_loss: 1.0621124505996704, val_acc: 0.46875
epoch: 68: train_loss: 1.1140373294480181, train_acc: 0.2410714328289032, val_loss: 1.0837566256523132, val_acc: 0.328125
epoch: 69: train_loss: 1.1133298280693238, train_acc: 0.3988095223903656, val_loss: 1.0627121329307556, val_acc: 0.421875
epoch: 70: train_loss: 1.112657515935495, train_acc: 0.3854166666666667, val_loss: 1.0661192536354065, val_acc: 0.421875
epoch: 71: train_loss: 1.1128552647100556, train_acc: 0.3452380994955699, val_loss: 1.037835955619812, val_acc: 0.5625
epoch: 72: train_loss: 1.1123745819749356, train_acc: 0.3229166666666667, val_loss: 1.044596254825592, val_acc: 0.46875
epoch: 73: train_loss: 1.1125994644186519, train_acc: 0.3065476218859355, val_loss: 1.058403193950653, val_acc: 0.46875
epoch: 74: train_loss: 1.1129973244667053, train_acc: 0.2931547661622365, val_loss: 1.0488380193710327, val_acc: 0.46875
epoch: 75: train_loss: 1.1123542098099726, train_acc: 0.4464285671710968, val_loss: 1.0788030624389648, val_acc: 0.375
epoch: 76: train_loss: 1.1114614711695419, train_acc: 0.4270833333333333, val_loss: 1.0782665014266968, val_acc: 0.375
epoch: 77: train_loss: 1.1114048107057555, train_acc: 0.3541666666666667, val_loss: 1.0822217464447021, val_acc: 0.375
epoch: 78: train_loss: 1.111134228827078, train_acc: 0.3586309552192688, val_loss: 1.0719571709632874, val_acc: 0.421875
epoch: 79: train_loss: 1.1112236902117727, train_acc: 0.3958333333333333, val_loss: 1.0318817496299744, val_acc: 0.5625
epoch: 80: train_loss: 1.1108548077045644, train_acc: 0.3705357114473979, val_loss: 1.0582601428031921, val_acc: 0.46875
epoch: 81: train_loss: 1.1104113086452325, train_acc: 0.3913690447807312, val_loss: 1.0664750337600708, val_acc: 0.421875
epoch: 82: train_loss: 1.110030984304037, train_acc: 0.3913690447807312, val_loss: 1.053269386291504, val_acc: 0.46875
epoch: 83: train_loss: 1.1098877352381507, train_acc: 0.3601190447807312, val_loss: 1.038710355758667, val_acc: 0.515625
epoch: 84: train_loss: 1.1098099451439052, train_acc: 0.3348214328289032, val_loss: 1.0752573609352112, val_acc: 0.375
epoch: 85: train_loss: 1.1101073456365007, train_acc: 0.3125, val_loss: 1.0445522665977478, val_acc: 0.46875
epoch: 86: train_loss: 1.110246071413559, train_acc: 0.3110119054714839, val_loss: 1.0614418983459473, val_acc: 0.421875
epoch: 87: train_loss: 1.109817702887636, train_acc: 0.3854166666666667, val_loss: 1.045192539691925, val_acc: 0.53125
epoch: 88: train_loss: 1.109242545308245, train_acc: 0.4568452338377635, val_loss: 1.0703997611999512, val_acc: 0.375
epoch: 89: train_loss: 1.1094597456631834, train_acc: 0.2961309552192688, val_loss: 1.0370798110961914, val_acc: 0.515625
epoch: 90: train_loss: 1.108554002129551, train_acc: 0.4494047562281291, val_loss: 1.0348254442214966, val_acc: 0.515625
epoch: 91: train_loss: 1.1080999404623886, train_acc: 0.4226190447807312, val_loss: 1.0487868189811707, val_acc: 0.46875
epoch: 92: train_loss: 1.10814175169955, train_acc: 0.3511904776096344, val_loss: 1.0293956398963928, val_acc: 0.5625
epoch: 93: train_loss: 1.1076721151669817, train_acc: 0.4494047562281291, val_loss: 1.059691607952118, val_acc: 0.421875
epoch: 94: train_loss: 1.1075952592648954, train_acc: 0.375, val_loss: 1.049126148223877, val_acc: 0.46875
epoch: 95: train_loss: 1.1076571059723692, train_acc: 0.3348214328289032, val_loss: 1.0458614826202393, val_acc: 0.46875
epoch: 96: train_loss: 1.1073441816769103, train_acc: 0.3735119005044301, val_loss: 1.031719148159027, val_acc: 0.515625
epoch: 97: train_loss: 1.1071956871318167, train_acc: 0.3407738109429677, val_loss: 1.0383647084236145, val_acc: 0.46875
epoch: 98: train_loss: 1.1069062647193368, train_acc: 0.3482142885526021, val_loss: 1.0643685460090637, val_acc: 0.421875
epoch: 99: train_loss: 1.1064068957169848, train_acc: 0.4122023781140645, val_loss: 1.042808711528778, val_acc: 0.46875
0.9617438316345215 0.59375
Accuracy of the network on the test images: 53%
F1 Score: 0.37375415282392027
precision_score: 0.2869897959183673
recall_total: 0.5357142857142857
Accuracy for class: Alligator Cracks is 0.0 %
F1 score: 0.0
precision_score: 0.0
recall_score: 0.0
Accuracy for class: Longitudinal Cracks is 0.0 %
F1 score: 0.0
precision_score: 0.0
recall_score: 0.0
Accuracy for class: Transverse Cracks is 100.0 %
F1 score: 0.37375415282392027
precision_score: 0.2869897959183673
recall_score: 0.5357142857142857
