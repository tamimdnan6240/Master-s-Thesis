Follwing classes are there : 
 ['Alligator Cracks', 'Longitudinal Cracks', 'Transverse Cracks']
data length: 132
Length of Train Data : 92
Length of Validation Data : 40
Alligator Cracks Alligator Cracks Transverse Cracks Transverse Cracks Transverse Cracks Transverse Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Longitudinal Cracks Transverse Cracks Alligator Cracks Transverse Cracks Transverse Cracks Transverse Cracks Alligator Cracks Transverse Cracks Transverse Cracks Transverse Cracks Longitudinal Cracks Alligator Cracks Longitudinal Cracks Transverse Cracks Transverse Cracks Transverse Cracks Longitudinal Cracks Alligator Cracks Alligator Cracks Transverse Cracks Transverse Cracks Alligator Cracks Longitudinal Cracks
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=512, out_features=3, bias=True)
    (3): Softmax(dim=1)
    (4): Dropout(p=0.5, inplace=False)
  )
)
epoch: 0: train_loss: 1.1424586375554402, train_acc: 0.3779761890570323, val_loss: 1.1011402606964111, val_acc: 0.234375
epoch: 1: train_loss: 1.139352798461914, train_acc: 0.3020833333333333, val_loss: 1.100190281867981, val_acc: 0.296875
epoch: 2: train_loss: 1.130817625257704, train_acc: 0.4285714228947957, val_loss: 1.1017060279846191, val_acc: 0.234375
epoch: 3: train_loss: 1.1203778286774955, train_acc: 0.4002976218859355, val_loss: 1.1027197241783142, val_acc: 0.1875
epoch: 4: train_loss: 1.106907653808594, train_acc: 0.5208333333333334, val_loss: 1.1038768291473389, val_acc: 0.1875
epoch: 5: train_loss: 1.1122148103184173, train_acc: 0.3452380994955699, val_loss: 1.105278491973877, val_acc: 0.171875
epoch: 6: train_loss: 1.1048659767423359, train_acc: 0.4434523781140645, val_loss: 1.0989145636558533, val_acc: 0.390625
epoch: 7: train_loss: 1.1028841783603034, train_acc: 0.3630952338377635, val_loss: 1.1017056703567505, val_acc: 0.28125
epoch: 8: train_loss: 1.1066592887595847, train_acc: 0.3764880994955699, val_loss: 1.1052971482276917, val_acc: 0.15625
epoch: 9: train_loss: 1.106755570570628, train_acc: 0.3898809552192688, val_loss: 1.1000046133995056, val_acc: 0.328125
epoch: 10: train_loss: 1.1084258122877644, train_acc: 0.4196428557236989, val_loss: 1.1095574498176575, val_acc: 0.25
epoch: 11: train_loss: 1.1113997134897444, train_acc: 0.2886904776096344, val_loss: 1.1014216542243958, val_acc: 0.34375
epoch: 12: train_loss: 1.109166301213778, train_acc: 0.4255952338377635, val_loss: 1.1006655097007751, val_acc: 0.296875
epoch: 13: train_loss: 1.1089037571634566, train_acc: 0.4360119005044301, val_loss: 1.1051205396652222, val_acc: 0.25
epoch: 14: train_loss: 1.1124112182193333, train_acc: 0.3407738109429677, val_loss: 1.097837746143341, val_acc: 0.34375
epoch: 15: train_loss: 1.112545559803645, train_acc: 0.3735119005044301, val_loss: 1.1048107147216797, val_acc: 0.25
epoch: 16: train_loss: 1.1120201746622722, train_acc: 0.3913690447807312, val_loss: 1.0960624814033508, val_acc: 0.34375
epoch: 17: train_loss: 1.1124138456803783, train_acc: 0.3675595223903656, val_loss: 1.095094084739685, val_acc: 0.390625
epoch: 18: train_loss: 1.113943426232589, train_acc: 0.2738095223903656, val_loss: 1.0969823598861694, val_acc: 0.34375
epoch: 19: train_loss: 1.1147747218608857, train_acc: 0.2931547661622365, val_loss: 1.1002355217933655, val_acc: 0.296875
epoch: 20: train_loss: 1.1134414313331482, train_acc: 0.3660714328289032, val_loss: 1.1027037501335144, val_acc: 0.296875
epoch: 21: train_loss: 1.1133482618765398, train_acc: 0.3363095223903656, val_loss: 1.0958512425422668, val_acc: 0.34375
epoch: 22: train_loss: 1.1112457738406416, train_acc: 0.3630952338377635, val_loss: 1.0950250625610352, val_acc: 0.34375
epoch: 23: train_loss: 1.1115538163317575, train_acc: 0.3809523781140645, val_loss: 1.104273796081543, val_acc: 0.25
epoch: 24: train_loss: 1.110897208849589, train_acc: 0.4136904776096344, val_loss: 1.1016498804092407, val_acc: 0.296875
epoch: 25: train_loss: 1.1122203469276428, train_acc: 0.3645833333333333, val_loss: 1.0999128222465515, val_acc: 0.296875
epoch: 26: train_loss: 1.1114972785667137, train_acc: 0.3943452338377635, val_loss: 1.091483235359192, val_acc: 0.34375
epoch: 27: train_loss: 1.1117874469075884, train_acc: 0.3898809552192688, val_loss: 1.08911794424057, val_acc: 0.34375
epoch: 28: train_loss: 1.108921858771094, train_acc: 0.4895833333333333, val_loss: 1.1042432188987732, val_acc: 0.296875
epoch: 29: train_loss: 1.1103016992410024, train_acc: 0.2782738109429677, val_loss: 1.0916216969490051, val_acc: 0.34375
epoch: 30: train_loss: 1.1085361389703647, train_acc: 0.46875, val_loss: 1.0980339050292969, val_acc: 0.296875
epoch: 31: train_loss: 1.1085532413174708, train_acc: 0.3526785671710968, val_loss: 1.0910687446594238, val_acc: 0.34375
epoch: 32: train_loss: 1.1070646246274312, train_acc: 0.4389880895614624, val_loss: 1.0901255011558533, val_acc: 0.34375
epoch: 33: train_loss: 1.1066670271695829, train_acc: 0.4107142885526021, val_loss: 1.0905035734176636, val_acc: 0.34375
epoch: 34: train_loss: 1.1064460226467678, train_acc: 0.4047619005044301, val_loss: 1.1087490320205688, val_acc: 0.25
epoch: 35: train_loss: 1.1057458404037688, train_acc: 0.4017857114473979, val_loss: 1.0736793279647827, val_acc: 0.390625
epoch: 36: train_loss: 1.106614720177006, train_acc: 0.3273809552192688, val_loss: 1.0946311354637146, val_acc: 0.296875
epoch: 37: train_loss: 1.1058382763151535, train_acc: 0.4360119005044301, val_loss: 1.0885252356529236, val_acc: 0.34375
epoch: 38: train_loss: 1.1049211998271127, train_acc: 0.4925595323244731, val_loss: 1.087441861629486, val_acc: 0.34375
epoch: 39: train_loss: 1.104711544016997, train_acc: 0.3809523781140645, val_loss: 1.1044405102729797, val_acc: 0.25
epoch: 40: train_loss: 1.103435966057506, train_acc: 0.4702380895614624, val_loss: 1.0954405069351196, val_acc: 0.296875
epoch: 41: train_loss: 1.103996430124555, train_acc: 0.3050595223903656, val_loss: 1.0580667853355408, val_acc: 0.4375
epoch: 42: train_loss: 1.1036366667858388, train_acc: 0.3869047661622365, val_loss: 1.0889996886253357, val_acc: 0.34375
epoch: 43: train_loss: 1.1028800426107461, train_acc: 0.3928571442763011, val_loss: 1.1017207503318787, val_acc: 0.296875
epoch: 44: train_loss: 1.1030310030336732, train_acc: 0.3779761890570323, val_loss: 1.0855162739753723, val_acc: 0.34375
epoch: 45: train_loss: 1.1028327406316563, train_acc: 0.4002976218859355, val_loss: 1.0910252928733826, val_acc: 0.34375
epoch: 46: train_loss: 1.1014977084829451, train_acc: 0.4627976218859355, val_loss: 1.0991882681846619, val_acc: 0.296875
epoch: 47: train_loss: 1.1005805027153757, train_acc: 0.4032738109429677, val_loss: 1.1006796956062317, val_acc: 0.296875
epoch: 48: train_loss: 1.0999539587773433, train_acc: 0.3928571442763011, val_loss: 1.0823162198066711, val_acc: 0.34375
epoch: 49: train_loss: 1.0997508192062377, train_acc: 0.3883928557236989, val_loss: 1.1037384867668152, val_acc: 0.296875
epoch: 50: train_loss: 1.0993873017286162, train_acc: 0.4315476218859355, val_loss: 1.1113733649253845, val_acc: 0.25
epoch: 51: train_loss: 1.0992231197082079, train_acc: 0.4002976218859355, val_loss: 1.08883398771286, val_acc: 0.34375
epoch: 52: train_loss: 1.0988420514190722, train_acc: 0.4479166666666667, val_loss: 1.0903087854385376, val_acc: 0.34375
epoch: 53: train_loss: 1.0975069510348048, train_acc: 0.4538690447807312, val_loss: 1.0858061909675598, val_acc: 0.34375
epoch: 54: train_loss: 1.0970614487474615, train_acc: 0.3854166666666667, val_loss: 1.1152687072753906, val_acc: 0.25
epoch: 55: train_loss: 1.0974980234390215, train_acc: 0.3839285721381505, val_loss: 1.0837940573692322, val_acc: 0.34375
epoch: 56: train_loss: 1.0981375477467366, train_acc: 0.3184523781140645, val_loss: 1.0753336548805237, val_acc: 0.390625
epoch: 57: train_loss: 1.0974262689036884, train_acc: 0.4255952338377635, val_loss: 1.1036535501480103, val_acc: 0.296875
epoch: 58: train_loss: 1.0968048899187208, train_acc: 0.4568452338377635, val_loss: 1.0615583658218384, val_acc: 0.4375
epoch: 59: train_loss: 1.096870388256179, train_acc: 0.3764880994955699, val_loss: 1.115597903728485, val_acc: 0.25
epoch: 60: train_loss: 1.097007631278429, train_acc: 0.3511904776096344, val_loss: 1.0715563297271729, val_acc: 0.390625
epoch: 61: train_loss: 1.0973698480795788, train_acc: 0.3735119005044301, val_loss: 1.128505527973175, val_acc: 0.203125
epoch: 62: train_loss: 1.0973087394679033, train_acc: 0.3511904776096344, val_loss: 1.0993703603744507, val_acc: 0.296875
epoch: 63: train_loss: 1.0967531437054274, train_acc: 0.4226190447807312, val_loss: 1.0977563261985779, val_acc: 0.296875
epoch: 64: train_loss: 1.0969108590712913, train_acc: 0.3958333333333333, val_loss: 1.0827392935752869, val_acc: 0.34375
epoch: 65: train_loss: 1.0958037972450254, train_acc: 0.4181547562281291, val_loss: 1.1154158115386963, val_acc: 0.25
epoch: 66: train_loss: 1.095181318657908, train_acc: 0.4375, val_loss: 1.0963010787963867, val_acc: 0.296875
epoch: 67: train_loss: 1.0950565051798724, train_acc: 0.3928571442763011, val_loss: 1.0910162925720215, val_acc: 0.296875
epoch: 68: train_loss: 1.0949617284507565, train_acc: 0.3199404776096344, val_loss: 1.0860236287117004, val_acc: 0.34375
epoch: 69: train_loss: 1.0948443810145057, train_acc: 0.3898809552192688, val_loss: 1.057882010936737, val_acc: 0.4375
epoch: 70: train_loss: 1.093908864567537, train_acc: 0.40625, val_loss: 1.1286773681640625, val_acc: 0.203125
epoch: 71: train_loss: 1.0937097704520928, train_acc: 0.3764880994955699, val_loss: 1.0853543281555176, val_acc: 0.34375
epoch: 72: train_loss: 1.0942551999875942, train_acc: 0.3229166666666667, val_loss: 1.067383587360382, val_acc: 0.390625
epoch: 73: train_loss: 1.0941075159085762, train_acc: 0.3809523781140645, val_loss: 1.1141082644462585, val_acc: 0.25
epoch: 74: train_loss: 1.0939243573612634, train_acc: 0.4226190447807312, val_loss: 1.0645004510879517, val_acc: 0.390625
epoch: 75: train_loss: 1.0941479391696156, train_acc: 0.3497023781140645, val_loss: 1.0812991857528687, val_acc: 0.34375
epoch: 76: train_loss: 1.0935306995462026, train_acc: 0.4538690447807312, val_loss: 1.0723415613174438, val_acc: 0.390625
epoch: 77: train_loss: 1.0935088892777758, train_acc: 0.3601190447807312, val_loss: 1.0929800868034363, val_acc: 0.296875
epoch: 78: train_loss: 1.093819955984751, train_acc: 0.3363095223903656, val_loss: 1.109866440296173, val_acc: 0.25
epoch: 79: train_loss: 1.0934776000678537, train_acc: 0.4211309552192688, val_loss: 1.0814145803451538, val_acc: 0.34375
epoch: 80: train_loss: 1.0939033313543214, train_acc: 0.3244047661622365, val_loss: 1.0779659152030945, val_acc: 0.34375
epoch: 81: train_loss: 1.0940123740735088, train_acc: 0.3482142885526021, val_loss: 1.0976195931434631, val_acc: 0.296875
epoch: 82: train_loss: 1.093189165534743, train_acc: 0.4255952338377635, val_loss: 1.0780993103981018, val_acc: 0.34375
epoch: 83: train_loss: 1.0933814093707095, train_acc: 0.3377976218859355, val_loss: 1.0649452805519104, val_acc: 0.390625
epoch: 84: train_loss: 1.093312929892072, train_acc: 0.3824404776096344, val_loss: 1.1041377186775208, val_acc: 0.25
epoch: 85: train_loss: 1.0933160479216608, train_acc: 0.3764880994955699, val_loss: 1.078191876411438, val_acc: 0.34375
epoch: 86: train_loss: 1.092790007362877, train_acc: 0.4047619005044301, val_loss: 1.1052512526512146, val_acc: 0.25
epoch: 87: train_loss: 1.0931526424758358, train_acc: 0.3363095223903656, val_loss: 1.0777860283851624, val_acc: 0.34375
epoch: 88: train_loss: 1.0939321886287643, train_acc: 0.2991071442763011, val_loss: 1.081933319568634, val_acc: 0.34375
epoch: 89: train_loss: 1.0935907180662505, train_acc: 0.4226190447807312, val_loss: 1.0873377919197083, val_acc: 0.34375
epoch: 90: train_loss: 1.0940482138277408, train_acc: 0.3452380994955699, val_loss: 1.1099324226379395, val_acc: 0.25
epoch: 91: train_loss: 1.0936550167591672, train_acc: 0.3898809552192688, val_loss: 1.0950175523757935, val_acc: 0.296875
epoch: 92: train_loss: 1.093584728283694, train_acc: 0.4017857114473979, val_loss: 1.0693073868751526, val_acc: 0.34375
epoch: 93: train_loss: 1.0931953388325708, train_acc: 0.4136904776096344, val_loss: 1.0969101786613464, val_acc: 0.296875
epoch: 94: train_loss: 1.0928747246139925, train_acc: 0.3630952338377635, val_loss: 1.0907085537910461, val_acc: 0.296875
epoch: 95: train_loss: 1.0924958963361049, train_acc: 0.4107142885526021, val_loss: 1.0647486448287964, val_acc: 0.390625
epoch: 96: train_loss: 1.0921912013050614, train_acc: 0.4255952338377635, val_loss: 1.082245647907257, val_acc: 0.34375
epoch: 97: train_loss: 1.0914138642703592, train_acc: 0.5014880895614624, val_loss: 1.0895128846168518, val_acc: 0.296875
epoch: 98: train_loss: 1.0909361317502928, train_acc: 0.4107142885526021, val_loss: 1.0408513247966766, val_acc: 0.4375
epoch: 99: train_loss: 1.0906889031330742, train_acc: 0.3869047562281291, val_loss: 1.0596035718917847, val_acc: 0.390625
0.9579690992832184 0.59375
GroundTruth:  Alligator Cracks Alligator Cracks Alligator Cracks Alligator Cracks
Accuracy of the network on the test images: 53 %
Accuracy for class: Alligator Cracks is 0.0 %
Accuracy for class: Longitudinal Cracks is 0.0 %
Accuracy for class: Transverse Cracks is 100.0 %
